{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_dir = 'C:/Users/KIMHAKBIN/A_My Python/Datacloud/digits/SVHN_mni/train'\n",
    "test_dir = 'C:/Users/KIMHAKBIN/A_My Python/Datacloud/digits/SVHN_mni/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7291 images belonging to 10 classes.\n",
      "Found 2007 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "#train_datagen.fit(images, augment=True, seed=seed)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size = (28,28),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size = (28,28),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model1 = models.Sequential()\n",
    "model1.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.MaxPooling2D((2,2)))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.Dropout(0.4))\n",
    "\n",
    "model1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.MaxPooling2D((2,2)))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.Dropout(0.4))\n",
    "\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dense(128, activation='relu'))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.Dropout(0.4))\n",
    "model1.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 199,722\n",
      "Trainable params: 198,890\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "114/114 [==============================] - 13s 111ms/step - loss: 2.4071 - acc: 0.2519 - val_loss: 1.5625 - val_acc: 0.5037\n",
      "Epoch 2/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 1.1369 - acc: 0.6299 - val_loss: 0.8235 - val_acc: 0.7459\n",
      "Epoch 3/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.7975 - acc: 0.7470 - val_loss: 0.6970 - val_acc: 0.7818\n",
      "Epoch 4/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.6789 - acc: 0.7884 - val_loss: 0.6766 - val_acc: 0.7937\n",
      "Epoch 5/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.6108 - acc: 0.8050 - val_loss: 0.6421 - val_acc: 0.7977\n",
      "Epoch 6/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.5646 - acc: 0.8229 - val_loss: 0.6272 - val_acc: 0.8037\n",
      "Epoch 7/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.5201 - acc: 0.8392 - val_loss: 0.5682 - val_acc: 0.8206\n",
      "Epoch 8/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.4853 - acc: 0.8419 - val_loss: 0.5647 - val_acc: 0.8266\n",
      "Epoch 9/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.4590 - acc: 0.8541 - val_loss: 0.4918 - val_acc: 0.8421\n",
      "Epoch 10/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.4378 - acc: 0.8618 - val_loss: 0.5531 - val_acc: 0.8256\n",
      "Epoch 11/60\n",
      "114/114 [==============================] - 5s 44ms/step - loss: 0.4085 - acc: 0.8666 - val_loss: 0.4919 - val_acc: 0.8485\n",
      "Epoch 12/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.3829 - acc: 0.8780 - val_loss: 0.5201 - val_acc: 0.8351\n",
      "Epoch 13/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.3786 - acc: 0.8766 - val_loss: 0.4654 - val_acc: 0.8595\n",
      "Epoch 14/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.3552 - acc: 0.8840 - val_loss: 0.5308 - val_acc: 0.8351\n",
      "Epoch 15/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.3377 - acc: 0.8907 - val_loss: 0.4767 - val_acc: 0.8495\n",
      "Epoch 16/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.3286 - acc: 0.9002 - val_loss: 0.4914 - val_acc: 0.8550\n",
      "Epoch 17/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.3191 - acc: 0.8993 - val_loss: 0.4267 - val_acc: 0.8635\n",
      "Epoch 18/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.2944 - acc: 0.9042 - val_loss: 0.5164 - val_acc: 0.8500\n",
      "Epoch 19/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.2949 - acc: 0.9011 - val_loss: 0.4919 - val_acc: 0.8525\n",
      "Epoch 20/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.2860 - acc: 0.9066 - val_loss: 0.4956 - val_acc: 0.8535\n",
      "Epoch 21/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.2650 - acc: 0.9162 - val_loss: 0.4930 - val_acc: 0.8525\n",
      "Epoch 22/60\n",
      "114/114 [==============================] - 5s 44ms/step - loss: 0.2591 - acc: 0.9136 - val_loss: 0.5397 - val_acc: 0.8341\n",
      "Epoch 23/60\n",
      "114/114 [==============================] - 5s 44ms/step - loss: 0.2539 - acc: 0.9201 - val_loss: 0.4364 - val_acc: 0.8660\n",
      "Epoch 24/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.2477 - acc: 0.9196 - val_loss: 0.4457 - val_acc: 0.8665\n",
      "Epoch 25/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.2414 - acc: 0.9199 - val_loss: 0.5113 - val_acc: 0.8480\n",
      "Epoch 26/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.2339 - acc: 0.9217 - val_loss: 0.4566 - val_acc: 0.8635\n",
      "Epoch 27/60\n",
      "114/114 [==============================] - 5s 44ms/step - loss: 0.2202 - acc: 0.9281 - val_loss: 0.4657 - val_acc: 0.8645\n",
      "Epoch 28/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.2145 - acc: 0.9287 - val_loss: 0.4730 - val_acc: 0.8685\n",
      "Epoch 29/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.2105 - acc: 0.9272 - val_loss: 0.4884 - val_acc: 0.8575\n",
      "Epoch 30/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.2049 - acc: 0.9313 - val_loss: 0.5617 - val_acc: 0.8440\n",
      "Epoch 31/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.2055 - acc: 0.9272 - val_loss: 0.4571 - val_acc: 0.8625\n",
      "Epoch 32/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1953 - acc: 0.9321 - val_loss: 0.5290 - val_acc: 0.8530\n",
      "Epoch 33/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1810 - acc: 0.9409 - val_loss: 0.5056 - val_acc: 0.8675\n",
      "Epoch 34/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1848 - acc: 0.9398 - val_loss: 0.5915 - val_acc: 0.8261\n",
      "Epoch 35/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1821 - acc: 0.9403 - val_loss: 0.5242 - val_acc: 0.8650\n",
      "Epoch 36/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1750 - acc: 0.9421 - val_loss: 0.4549 - val_acc: 0.8695\n",
      "Epoch 37/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1718 - acc: 0.9399 - val_loss: 0.5772 - val_acc: 0.8276\n",
      "Epoch 38/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1666 - acc: 0.9418 - val_loss: 0.4833 - val_acc: 0.8605\n",
      "Epoch 39/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1632 - acc: 0.9454 - val_loss: 0.4848 - val_acc: 0.8719\n",
      "Epoch 40/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1666 - acc: 0.9440 - val_loss: 0.4958 - val_acc: 0.8690\n",
      "Epoch 41/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1609 - acc: 0.9465 - val_loss: 0.4978 - val_acc: 0.8640\n",
      "Epoch 42/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1660 - acc: 0.9439 - val_loss: 0.4907 - val_acc: 0.8714\n",
      "Epoch 43/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1601 - acc: 0.9444 - val_loss: 0.4667 - val_acc: 0.8809\n",
      "Epoch 44/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1526 - acc: 0.9506 - val_loss: 0.4911 - val_acc: 0.8600\n",
      "Epoch 45/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1466 - acc: 0.9503 - val_loss: 0.4699 - val_acc: 0.8774\n",
      "Epoch 46/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1476 - acc: 0.9499 - val_loss: 0.5171 - val_acc: 0.8705\n",
      "Epoch 47/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1412 - acc: 0.9501 - val_loss: 0.4644 - val_acc: 0.8814\n",
      "Epoch 48/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1340 - acc: 0.9528 - val_loss: 0.4991 - val_acc: 0.8685\n",
      "Epoch 49/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1463 - acc: 0.9493 - val_loss: 0.4850 - val_acc: 0.8769\n",
      "Epoch 50/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1323 - acc: 0.9590 - val_loss: 0.4655 - val_acc: 0.8734\n",
      "Epoch 51/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1353 - acc: 0.9546 - val_loss: 0.5290 - val_acc: 0.8680\n",
      "Epoch 52/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1391 - acc: 0.9549 - val_loss: 0.5009 - val_acc: 0.8710\n",
      "Epoch 53/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1215 - acc: 0.9592 - val_loss: 0.5500 - val_acc: 0.8710\n",
      "Epoch 54/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1341 - acc: 0.9505 - val_loss: 0.5089 - val_acc: 0.8680\n",
      "Epoch 55/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1254 - acc: 0.9578 - val_loss: 0.5366 - val_acc: 0.8650\n",
      "Epoch 56/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1232 - acc: 0.9576 - val_loss: 0.5821 - val_acc: 0.8475\n",
      "Epoch 57/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1359 - acc: 0.9557 - val_loss: 0.4901 - val_acc: 0.8700\n",
      "Epoch 58/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1131 - acc: 0.9619 - val_loss: 0.5455 - val_acc: 0.8580\n",
      "Epoch 59/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1172 - acc: 0.9602 - val_loss: 0.4663 - val_acc: 0.8719\n",
      "Epoch 60/60\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.1109 - acc: 0.9612 - val_loss: 0.4983 - val_acc: 0.8829\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit_generator(train_generator,\n",
    "                               steps_per_epoch=114, \n",
    "                               epochs=60,\n",
    "                               validation_data=validation_generator,\n",
    "                               validation_steps=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
